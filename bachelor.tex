\documentclass[parskip=half]{scrreprt}
\usepackage{fontspec}
\usepackage{multicol}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{csquotes}
\usepackage{minted}
\usepackage{tikz}
\usepackage{chngcntr}
\usepackage{amstext}
\usepackage[normalem]{ulem}

% red underline, nice for correction things
% http://tex.stackexchange.com/questions/7321/how-to-color-just-the-wave-produced-by-the-ulem-package
\makeatletter
\def\uwave{\bgroup \markoverwith{\lower3.5\p@\hbox{\sixly \textcolor{red}{\char58}}}\ULon}
\font\sixly=lasy6 % does not re-load if already loaded, so no memory problem.
\makeatother

% Define additional header fields
\makeatletter
\newcommand\Doctype[1]{\renewcommand\@Doctype{#1}}
\newcommand\@Doctype{\@latex@error{No \noexpand\Doctype given}\@ehc}

\newcommand\doctype[1]{\renewcommand\@doctype{#1}}
\newcommand\@doctype{\@latex@error{No \noexpand\doctype given}\@ehc}

\newcommand\germanTitle[1]{\renewcommand\@germanTitle{#1}}
\newcommand\@germanTitle{\@latex@error{No \noexpand\germanTitle given}\@ehc}

\newcommand\supervisor[1]{\renewcommand\@supervisor{#1}}
\newcommand\@supervisor{\@latex@error{No \noexpand\supervisor given}\@ehc}

\newcommand\advisor[1]{\renewcommand\@advisor{#1}}
\newcommand\@advisor{\@latex@error{No \noexpand\advisor given}\@ehc}

\newcommand\location[1]{\renewcommand\@location{#1}}
\newcommand\@location{\@latex@error{No \noexpand\location given}\@ehc}
\makeatother

% do not restart counters on every chapter
% provided by the chngcntr package
\counterwithout{footnote}{chapter}

\newcommand\inline[1]{{\addfontfeature{Letters=SmallCaps}#1}}

\Doctype{Bachelor's thesis}
\doctype{bachelor's thesis}

\author{Marek Kubica}
\title{A functional streaming API for OCaml}
\germanTitle{Eine funktionale Programmierschnittstelle für Datenströme in OCaml}
\supervisor{Prof. Dr. Alois Knoll}
\advisor{Markus Weißmann, M.Sc.}
\location{München}
\date{\today}

\setmainfont{Linux Libertine O}
\setsansfont{Linux Biolinum O}
\setmonofont[Scale=MatchUppercase]{Droid Sans Mono Dotted}

\usemintedstyle{tango}

\hypersetup{
%	bookmarks=true,          % show bookmarks bar?
%	unicode=false,           % non-Latin characters in Acrobat’s bookmarks
%	pdftoolbar=true,         % show Acrobat’s toolbar?
%	pdfmenubar=true,         % show Acrobat’s menu?
%	pdffitwindow=false,      % window fit to page when opened
	pdfstartview={FitH},     % fits the width of the page to the window
	pdftitle={A functional streaming API for OCaml},     % title
	pdfauthor={Marek Kubica},   % author
	pdfsubject={Bachelor's thesis}, % subject of the document
%	pdfcreator={Creator},    % creator of the document
%	pdfproducer={Producer},  % producer of the document
	pdfkeywords={ocaml} {libarchive} {functional}, % list of keywords
%	pdfnewwindow=true,       % links in new window
	colorlinks=true,         % false: boxed links; true: colored links
	linkcolor=black,         % color of internal links (original: red)
%	linktoc=section          % which part of a toc-entry to link (possible: none, section, page, all)
	citecolor=black,         % color of links to bibliography (original: green)
	filecolor=black,         % color of file links (original: magenta)
	urlcolor=black,          % color of external links (original: cyan)
%	linkbordercolor={1 0 0}, % color of frame around internal links (if colorlinks=false)
%	citebordercolor={0 1 0}, % color of frame around citations (if colorlinks=false)
%	urlbordercolo={0 1 1}    % color of frame around URL links (if colorlinks=false)
}

\providecommand*{\listingautorefname}{Listing}
\hyphenation{lib-ar-chi-ve}

\begin{document}

\input{cover}
\input{titlepage}
\input{disclaimer}

\phantomsection
\addcontentsline{toc}{chapter}{Abstract}
\begin{abstract}
	\subsubsection*{\abstractname}
	TODO
\end{abstract}

\tableofcontents

\chapter{Introduction}
\label{sec:intro}

Processing data is the use-case computers were invented for: doing calculations
that are too complicated for manual computation or too time-consuming.
Therefore, in the history of computing the representation of data was always
very important. Usual hardware architectures used only to operate on scalar
values, because the registers of CPUs could only store scalar values.

Computers are very good at repeating tasks, so it is only natural to extend the
processing of one record to processing multiple records on which the
computation is repeated. Early computers worked on data in a batch structure,
by reading a record from punch cards, computing the result and writing the
result to punch cards. Later systems used their built-in memory to hold the
data and multiple ways to organize this data were possible.

One way to organize was using fixed-size arrays of values on which one
particular operation was executed. Languages organizing data this way are APL
and its sucessors J and K for example. Another example is the x86 assembly
language with its special-purpose MMX and SSE extensions which compute on sets
of registers holding floating point values.

An alternative is the \emph{list} abstraction. Seemingly similar to arrays, the
high-level difference with lists is that lists do not usually have a fixed
length. While arrays are usually implemented as sequence of data in memory,
list implementations can be very flexible with different advantages and
disadvantages. A very important language family that utilizes lists heavily is
Lisp where even the source code is written in a list structure. Usually, all
modern languages provide a convenient way to handle lists, many also provide
syntactic extensions.

In functional programming in particular, lists have been very important. Many
languages utilize operators like \inline{first} and \inline{rest} to get the
first element of the list and the remainder of the list. The second element can
be expressed via \inline{first}, \inline{rest} and recursion. OCaml in
particular provides \emph{pattern matching} and a special syntax to destructure
lists in this way.

An evolution of lists is the \emph{sequence} abstraction. Lists are limited by
the available memory to hold all the records, whereas a sequence does not need
to.  To make this possible, sequences sacrifice some features of lists like
random access on each record and instead provide a way to get the first
element. As we saw, in the context of functional programming, this restriction
is not problematic as other ways to work with this data exist.

These sequences might be \emph{lazy}, meaning that the sequence can be created
without having to evaluate all values of itself. These values need only be
evaluated when the head of the sequence is requested.

OCaml is currently missing a solid implementation of these streams, therefore
the objective in this bachelor's thesis is to provide a functional
implementation of streams that can be composed. The effectiveness of this
stream library is then demonstrated by building a library for data compression
on top of it.

\chapter{Overview of existing solutions}
\label{sec:solutions}

Lazy streams are a feature that many languages support since there is one
specific use-case that nearly all languages support and that can only be
reasonably implemented with a veriant of lazy streams: file handling.

Most systems allow files to grow much larger than the operating memory of the
system, therefore holding all data in memory is impossible. Yet languages need
to support reading and writing such files. So the languages need to have an
implementation of a data type that can be read incrementally, without having to
hold it completely in memory.

A number of popular languages were picked with interesting and contrasting
approaches on this issue, so the advantages and disadvantages can be analyzed.
The insights are used to propose of a good solution for OCaml.

\section{C}
\label{sec:c}

The C programming language hardly needs any introduction, considering it is
among the most widely used programming languages. Unlike many others, the C
programming language is rather old and lacking some modern features. The C type
system essentially only knows about numbers: pointers are a special case of
numbers and strings are also represented as arrays of numbers.

Therefore, with the lack of syntactic support many libraries have to emulate
functionality using functions and macros. One very fundamental library for C is
of course the Standard Library (\enquote{stdlib}) which is usually provided by
a library called \enquote{libc} and shipped by the operating system.

This basic library provides functions for handling strings, copying data in a
convenient way, handling files and many more. In fact, handling files is one of
the tasks where streaming data is useful since otherwise the whole file would
need to fit completely in memory. When C was first designed, main memory was
several magnitudes smaller than currently, so the designers had to come up with
a solution.

The C solution is to use an interface that comes directly from the operating
system: file descriptors. File descriptiors (FDs) are basically just integer
numbers that reference an opened file. This concept can be even considered lazy
evaluated, since opening a file does not require reading its contents. In C,
file descriptors are usually wrapped in a data type called \inline{FILE}, but
working directly with the descriptors directly is also possible, if somewhat
less convenient.

A file is read by using a stdlib function called \inline{fread} which takes a
buffer as a first argument, as location on where to save the data read in main
memory, a size indicator for letting the system know how big one element of the
buffer is, a count, to notify how many elements to read and finally an opened
file, wrapped by the \inline{FILE} type\footnote{A similar function
\inline{read} does the same thing with a file descriptor instead of a
\inline{FILE}}. An analogous functionality is implemented by \inline{fwrite} to
write data to files.

This functionality seems limited to files, but that is not the case. C also
knows 3 \enquote{files} that are not actually files: \inline{stdin} for reading
data from the user, \inline{stdout} for writing output to the user and
\inline{stderr} for writing error output. These references can be used where a
\inline{FILE} is required and do not need to be saved to disk. Thus C has
\emph{some} support for streaming data.

\begin{listing}[H]
  \inputminted[linenos]{c}{readfile.c}
  \caption{Reading file line by line in C TODO \url{http://rosettacode.org/wiki/Read\_a\_file\_line\_by\_line\#C}}
  \label{lst:creadfile}
\end{listing}

\autoref{lst:creadfile} shows how file I/O looks in C. One should note that
this code is not portable C because it uses \inline{fgetln} which is only
available in the C standard library on BSD systems. Yet the example demonstrates
how the \inline{FILE} type is used.

With a streaming API in place, there are a number of tasks that are a natural
fit, for example compression of data. An uncompressed data stream gets in, a
compressed stream comes out with the encryption function as a bleack box. Such
compression algorithms exist since years and are very popular and common.
Examples include gzip~\cite{rfc1952} and
bzip2\footnote{\url{http://bzip.org/}}, each tailored to different use cases:
good compression ratio, fast decompression, good compression ratios on specific
types of data etc.

Libraries for these algorithms are implemented most of the time in C
(\inline{zlib} for gzip, \inline{libbz2} for bzip2) or at least have an
interface to be used from C (LZMA reference implementation\footnote{7-Zip
project, \url{http://www.7-zip.org/}}), therefore giving implementers in C a
wide variety to choose from. Unfortunately, these libraries all provide
different APIs, so just switching the compression algorithm from gzip to bzip2
is not very convenient.  This problem can be solved with
libarchive\footnote{\url{http://www.libarchive.org}}, a wrapper around a huge
amount of different compression libraries. Furthermore, libarchive provides
implementations of common container formats like \inline{TAR} or \inline{ZIP}.

For this bachelor's thesis, implementing compression algorithms is
out-of-scope, so using libarchive as a way to implement compression
functionality is a perfect fit. One big advantage of libarchive is that it is a
universal wrapper, so adding new algorithms can be done completely within
libarchive while all users of libarchive, like this bachelor thesis, can profit
and do not suffer duplication of efforts.

\section{Java}
\label{sec:java}

The Java programming language is an imperative object-oriented language with
support for classes as well as formal interfaces for classes to implement. In
this context, it is interesting to see how Java handles streams and iteration
as these concepts are tightly interlocked.

\subsection{Iterable}
\label{sec:jiterable}

\enquote{Classic} Java, that is Java before version 1.5\footnote{Sometimes
called Java 5} did not have any syntactic support for iteration, so the
canonical way was to use a \inline{for}-loop and call the \inline{iterator}
method on objects that support the \inline{Iterable} interface. This method
returns an object that implements the \inline{Iterator} interface, like shown
in \autoref{lst:jiter}.

\begin{listing}[H]
  \begin{minted}[linenos]{c}
for (Iterator<TimerTask> i = collection.iterator(); i.hasNext(); ) {
    i.next().cancel();
}
  \end{minted}
  \caption{Classic iteration without syntactic sugar}
  \label{lst:jiter}
\end{listing}

% TODO: source http://docs.oracle.com/javase/1.5.0/docs/guide/language/foreach.html

The \inline{Iterator} interface defines three methods: \inline{hasNext} to
determine whether the end of the iterator was reached, \inline{next} to return
the next element of the iterator and an optional method \inline{remove} to
remove the last element of the collection over which the iterator is iterating.

Java 1.5 extended the \inline{for}-loop to do the iterator management
automatically, which does the creation of the iterator automatically, as in
\autoref{lst:jiter5}. With the addition of generics in Java 1.5, the
\inline{next} method was changed to return an element of the containing type
instead of an Object that needed to be cast to the desired type, thus improving
type safety.

\begin{listing}[H]
  \begin{minted}[linenos]{c}
for (TimerTask t : collection) {
    t.cancel();
}
  \end{minted}
  \caption{Java 1.5-style iteration with syntactic sugar}
  \label{lst:jiter5}
\end{listing}

\subsection{I/O Streams}
\label{sec:jio}

\section{Python}
\label{sec:python}

Python is a dynamically-typed high level language designed in the the Nineties
and enjoying constant improvement. It has seen rising adoption in the last few
years in scientific communities as well as for web development. Much of this
apotion can be attributed to the simplicity of the language and the thriving
ecosystem.

One important concept in Python is so called
\emph{duck-typing}\footnote{\emph{If it walks like a duck, if it quacks like a
duck, then it is a duck} is the typical explanation of this term} in which
there is no formal interface like in Java but rather objects that provide
specific behaviors.

This means that every object can support any interface, as long as it provides
the proper methods and returns the proper values. No special definitions are
required and there is no required class hierarchy.

\subsection{Iterables}
\label{sec:pyiterable}

One important interface in Python is the \emph{Iterable}, that is an object
over which it is possible to iterate. Iterables are only required to support
very limited operations:

\begin{itemize}

  \item Provide a \inline{\_\_next\_\_} method which returns the next value of
	  the iterable.

  \item Throw a \inline{StopIteration} exception after the last element was
	  returned.  This is used to denote that the iterable was consumed and
	  will not provide any more values.

\end{itemize}

Python's built-in datatypes support this interface, therefore implementing
these interfaces in custom types enables the standard Python syntax to use them
just like every other type. In particular, lists support this interface but
also strings and files as well.

\begin{listing}[H]
  \inputminted[linenos]{python}{iterable.py}
  \caption{An iterable in Python}
  \label{lst:pyiterable}
\end{listing}

\autoref{lst:pyiterable} shows a very simple implementation of an iterable
object. The object returns values indefinitely, so just the first five are
retrieved.

Python also has additional syntactic support for so called \emph{generators}
which are ordinary functions that use the \inline{yield} keyword instead of the
\inline{return} keyword. This causes the functions return value to turn into an
iterable, return the value and suspend. Each element of the iterable causes the
function to resume and run until the next \inline{yield} is reached.  Reaching
the end of the function or a \inline{return} statement causes a
\inline{StopIteration} exception being thrown. This exception is interpreted by
the \inline{for} loop as end-marker, thus stopping to iterate over the
generator. \autoref{lst:pygenerator} demonstrates a simple generator in action.

\begin{listing}[H]
  \inputminted[linenos]{python}{generator.py}
  \caption{A simple generator}
  \label{lst:pygenerator}
\end{listing}

Python's support for generators goes even further by making it possible to pass
values into a function that was suspended when it reached a \inline{yield}
keyword, although the details and syntactic extensions of Python generators are
outside of the scope of discussion.

\subsection{File-like objects}
\label{sec:pyfile}

A very useful concept in Python is the so-called \enquote{file-like object}.
\enquote{file-like} objects are a simple abstraction of a file in the
filesystem, similar to C's \inline{FILE} data type. Unlike C,
\enquote{file-like} objects don't need to be of any specific type but are
required to provide a specific interface in a duck-typing manner.

The first \enquote{file-like object} in Python was the object returned by the
function \inline{open} which returns a reference to an open file, similar to
\inline{fopen} in C. The type of this object is \inline{file} which explains
the naming of \enquote{file-like} objects.

A \enquote{file-like} object usually provides a minimal interface of a
\inline{read} method for files that are meant for reading and \inline{write}
for files that are meant for writing. \inline{read} takes an optional integer
parameter which specifies how many bytes to read at maximum, whereas the
default is to read the data until the end. The write method takes a
string\footnote{Python 2.x uses the \inline{str}-bytestring type, Python 3.x
uses either the \inline{str} Unicode string type or \inline{bytes} type} and
writes it to the file. The interface is very simple but for real files it can
also be extended by adding methods to seek inside of a file, getting the inode
number of the file etc.

\enquote{file-like} objects are very useful to deal with code that requires a
reference to a file but the file to be used is not on a local file system and
cannot be opened using \inline{open}. Examples of such files include files in
archives like a text-file inside a ZIP archive or remote files like a file on a
HTTP server. \autoref{lst:pyremote} creates such a \enquote{file-like}
object, which can be processed by most functions that expect to work with
files.

\begin{listing}[H]
  \inputminted[linenos]{python}{remote.py}
  \caption{A \enquote{file-like object} from a URL}
  \label{lst:pyremote}
\end{listing}

Iteration semantics over a \enquote{file-like} object are not defined by the
interface, but iteration over proper \enquote{file} objects causes Python to
iterate over the lines in a lazy fashion: each line is only read on demand and
discarded afterwards. This enables Python to read files of arbitrary size using
this interface.

\chapter{Implementation}
\label{sec:implementation}

Implementing a functional streaming API in specifically in OCaml has a couple
of advantages. OCaml enables type-safe development which is useful for
environments where the reliability of software is crucial and having code that
can be proven correct by the type inference is a big advantage. Although it
does not obsolete thorough unit testing, a type-safe language can provide some
amount of extra security.

The OCaml compiler can generate byte-code as well as native code for a range of
platforms\footnote{The Debian project lists AMD64, ARM, x86, Itanium, MIPS,
PowerPC, S390 and SPARC as supported platforms, see
\url{http://packages.debian.org/squeeze/ocaml}} and is well known for
well-performing code. Thus the choice of OCaml as an implementation language is
obvious.

A recent advance in the OCaml community has been the introduction of OPAM, a
package manager along with a catalogue of packages available for programmers.
OPAM can be roughly compared to systems like the CPAN for Perl, the Python
Package Index (PyPI) as well as the CTAN for \LaTeX. This development was made
possible by the convergence to a common package description tool, OASIS. OASIS
defines a format to describe package metainformation like name, version number,
short description as well as instruction on how to build it. The concept of
OASIS can be compared roughly to build tools like GNU autotools or CMake and
also Cabal for Haskell.

Experience has shown that much software developed in university context has
received poor reception in the open software community. Often this has not been
the case because the software was not \emph{useful}, but the state of said
software was easy enough to use for other non-university programmers.

As such, while implementing this software, great care has been exercised to
adhere to current OCaml community practices, so potential users and
contributors will not be put off by idiosyncracies of software developed in
isolation. This means that the software will use OASIS and the finished package
will be available in the OPAM package directory under a Free Software license.

\section{Architecture}
\label{sec:architecture}

As outlined before, implementing everything from scratch would take long time
and be quite useless, therefore OStreamer uses existing code, extending it
where possible. An overview of the system architecture is provided by
\autoref{fig:architecture}.

\begin{figure}[h]
  \centering
  \input{architecture}
  \caption{High-level view of system architecture. The lowest level are usually
    C~libraries that provide functionality, the middle-tier are wrapper
    libraries. OStreamer is on the highest level, providing a universal interface
    to these libraries. The highlighted part is implemented, the rest are
    possible extensions.}
  \label{fig:architecture}
\end{figure}

\section{Compression}
\label{sec:compression}

There are many possibilities to demonstrate the use of a streaming library so
to find an application which is interesting enough for the thesis while not too
complex to exceed the scope, compression is a good fit.

From the viewpoint of the OCaml software ecosystem, this pick makes sense, as
there is no widely adopted software library to deal with compression in a
universal way. There is a number of solutions an OCaml programmer can choose
from, but each suffers from some problems.

\subsection{Possible alternatives}
\label{sec:alternatives}

There is some selection in solutions that cover only some of the functionality
that is usually expected from a compression library.

\begin{itemize}
  \item camlzip\footnote{\url{https://forge.ocamlcore.org/projects/camlzip/}}:
    Mature library, but supports only Zip archives. One specific limitation is
    the lack of support for in-memory data which requires to read and write
    temporary files causing bad performance. Also, appears to be in maintenance
    mode with hardly any changes in the last years.
  \item OCamlBZ2\footnote{\url{https://forge.ocamlcore.org/projects/camlbz2/}}:
    This library is limited to handle only bz2 compression and is a direct
    binding to libbz2. Maintenance of the library seems to have stopped many
    years ago after only two releases. One disadvantage is that raw bz2
    streams are rare — usually multiple files are wrapped in tar archives,
    for which this library has no support.
  \item ocaml-tar\footnote{\url{https://github.com/samoht/ocaml-tar}}:
    implements tar format archives in pure OCaml code. This implements
    \emph{one} type of tar, whereas libarchive supports multiple variants.
  \item ocaml-archive\footnote{\url{https://forge.ocamlcore.org/projects/ocaml-archive/}}:
    The most comparable library to this effort, unfortunately not a complete
    binding and only one single version ever released that binds an old version
    of libarchive that is considered \enquote{legacy} by the libarchive
    developers. In addition, this binding is incomplete and does not feature
    compression support. Yet useful for transfering some ideas on how to
    implement the C binding.
\end{itemize}

\subsection{libarchive}
\label{sec:libarchive}

libarchive\footnote{\url{http://www.libarchive.org/}} is a library designed to
handle all compression needs for low-level programming. It originated in the
FreeBSD project but is also used by many other systems. One of the problems
before libarchive was that different libraries like zlib (gzip) and libbz2
(bz2) have different interfaces, so to add support for a particular format, the
developer needed to do a tedious effort to add support manually. Also, some
compression formats require container formats, e.g. the popular ZIP format
consists of a format to bundle files which are in turn separately compressed
using \enquote{deflate} and \enquote{store} algorithms. A similar case is the
TAR (\enquote{Tape ARchive}) format popular on Unix which bundles files in one
single file and usually gets compressed using a regular compressor. The TAR
format does not have a canonical implementation -- there are separate
implementations by the GNU project, the BSD project, in the Python Standard
Library etc. Usually programmers have reimplement the format and its variants.

Libarchive solves this by providing a common interface to two mechanisms:
container formats, called \enquote{formats} in libarchive as well as
compression formats, called \enquote{filters}. Not all formats that can be read
can also be written, but the variety of options that libarchive supports is
quite huge.

Formats supported be libarchive include:

\begin{itemize}
  \item \emph{7z}, the compression format of 7-Zip
  \item \emph{AR}, used for static libraries in Unix
  \item \emph{CAB}, Microsoft cabinet files for installers, read-only support
  \item \emph{CPIO}, initial ramdisk for booting a GNU/Linux system
  \item \emph{ISO 9660}, CD-ROM image files
  \item \emph{LHA}, popular compression format in Japan, read-only support
  \item \emph{RAR}, compression format of WinRAR, read-only support
  \item \emph{TAR}, typical file exchange format in Unix systems, with
    \emph{ustar}, \emph{GNU} and \emph{PAX} variants supported.
  \item \emph{XAR}, format used by the RPM5 package manager
  \item \emph{ZIP}, most popular archive format
\end{itemize}

Apart from these formats libarchive also supports various compression filters:

\begin{itemize}
  \item \emph{bzip2}, popular alternative to \emph{gzip} with better compression
  \item \emph{compress}, a mostly obsolete compression format (\inline{.Z})
    used on Unix
  \item \emph{grzip}, a compressor that applies special preprocessing
  \item \emph{gzip}, a popular format with decent compression and decent speed
  \item \emph{lrzip}, compressor with multiple compression backends (LZMA, ZPAQ,
    LZO, gzip, bzip2)
  \item \emph{LZO}, an algorithm designed with very fast decompression in mind
  \item \emph{RPM}, packages for the RPM package manager used in Fedora Linux,
    openSUSE and a variety of other distributions
  \item \emph{UU}, UUencode, a way to encode 8 bit data into printable ASCII
    characters
  \item \emph{XZ}, a compressor with high compression using the LZMA2 algorithm
    from 7-Zip
\end{itemize}

In addition to the provided support, it is also possible to create own filters
by registering external programs that libarchive will call and interface
automatically, so creating new filters is very simple.

libarchive also provides \inline{bsdtar}, a program with a command line
interface similar to \inline{tar} but with support for all formats that
libarchive supports, providing a consistent interface for handling all kinds of
archive files from the command line.

When trying to read files that are not in a specific container format,
libarchive uses the so-called \enquote{raw} format, which just runs a filter.
This is useful to decompress files that are just processed with e.g. gzip but
not in a tar file. During implementation it turned out that there was only a
format for \emph{reading} raw files, but \emph{writing} these was not possible.

A patch for libarchive was written to add such a filter and submitted to the
upstream author. After a number of revisions on functionality and code style \&
conventions, the patch was added to the upstream version of libarchive,
together with unit tests.

Adding new formats to libarchive is essentially simple, since it provides hooks
for implementing own formats. \autoref{lst:archiveformat} sets these hooks in
the lines 14 to 23. Not implemented hooks are not used, although another bug
with handling unset (\inline{NULL}) callbacks, for which another patch was
created and submitted to the upstream author.

\begin{listing}[h]
  \inputminted[linenos,fontsize=\small]{c}{archive-set-format.c}
  \caption{Initializing a format}
  \label{lst:archiveformat}
\end{listing}

Special care was taken in the raw format to only allow one file entry to be
written to the archive, as \autoref{lst:archiveheader} demonstrates. This entry
also gets limited to be a regular file, since other file types do not make
sense.

\begin{listing}[h]
  \inputminted[linenos,fontsize=\small]{c}{archive-write-header.c}
  \caption{Checks for file type and number of files attempted to write}
  \label{lst:archiveheader}
\end{listing}

Writing the raw data is the simplest part, evidenced by
\autoref{lst:archivedata}.

\begin{listing}[h]
  \inputminted[linenos,fontsize=\small]{c}{archive-write-data.c}
  \caption{Writing data into a \enquote{raw} format file}
  \label{lst:archivedata}
\end{listing}

With this functionality available, an OCaml wrapper on top of libarchive can be
constructed.

\subsection{Foreign function interface}
\label{sec:ffi}

\section{Low-level binding}
\label{sec:lowlevel}

\subsection{Memory allocator}
\label{sec:allocator}

For writing out compressed data, libarchive supports a number of modes:

\begin{itemize}
  \item Writing to a file
  \item Writing to a file descriptor
  \item Writing to a memory buffer
  \item A custom function
\end{itemize}

These functions are very useful when writing code directly using the C API,
since writing to file and to file descriptors saves the programmer from having
to do anything besides opening a file or file descriptor and libarchive handles
writing out the data itself. Unfortunately, these modes cannot be used for a
stream interface, since at the point of writing the compressed data, it is not
yet known what to do with the data: save it to a file or maybe stream it
through a socket to some remote computer. In the latter case, saving the data
to disk would serve no point.

Therefore, the stream interface in this library needs libarchive to write the
compressed data into memory. libarchive also provides such a function,
unfortunately this function saves into a \emph{fixed} memory buffer. This
creates a number of problems since it is not known how big an archive that is
produced by libarchive will be. It might turn out very small on efficient
compression, e.g. text, in which case a fixed buffer is not used and lot of
memory is wasted. On the other hand, when compressing already compressed data
like compressed music or movies, it might turn out even larger than before,
thus overflowing a buffer.

To prevent overflows yet using the memory efficiently, the wrapper code in this
thesis uses a smarter approach: the buffer is resized while writing the
archive. There are distinct goals that are to be optimized:

\begin{enumerate}
  \item Safety: The buffer should never overflow as this causes memory
    corruption which leads to incorrect behaviour and security problems
  \item Resource-saving: The buffer should not waste unnecessary memory
  \item Efficiency: Due to how memory allocation works, a minimal number
    of resize operations are desirable, since each resize might require
    to copy previous contents of the buffer
\end{enumerate}

Before each write, the buffer is checked to make sure there is enough space
left in the buffer to save the data. The goal of being resource friendly would
be fulfilled by resizing the buffer to the desired size to fit the data, but
this will cause many resize operations. As a measure against this, the buffer
gets resized using an empiric formula:

\begin{displaymath}
\text{new\_length} = \lfloor 1.5 \times \text{current\_length} \rfloor
\end{displaymath}

This factor is a compromise between memory-usage and number of allocations. If
the buffer required is small, it will not waste much memory, if the buffer
required is huge, there will be less resize operations required. In addition,
the initial buffer size is $4096$~byte, to prevent lots of small resize
operations at the beginning. After each new size calculation, the new buffer
size is sanity-checked whether it really fits the new data.

The simple algorithm used prevents excessive resizes while minimizing memory
usage.

\section{Functional streaming interface}
\label{sec:functional}

\chapter{Discussion}
\label{sec:discussion}

\bibliographystyle{plain}
\bibliography{bachelor}
\end{document}
